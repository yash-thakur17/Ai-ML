{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5e0d9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0397222",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_Path = 'C:/Users/Admin/OneDrive/Desktop/Yash/python/internship project/aiml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc96f0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Datagen = ImageDataGenerator(\n",
    "    rescale =1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "692131ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_hight = 150\n",
    "img_width = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "548618c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2152 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "Train_Genrator = Train_Datagen.flow_from_directory(\n",
    "    file_Path,\n",
    "    target_size = (img_hight,img_width),\n",
    "    batch_size = batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "799a8b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Potato___Early_blight': 0, 'Potato___Late_blight': 1, 'Potato___healthy': 2} \n",
      "\n",
      "[0 0 0 ... 2 2 2] \n",
      "\n",
      "2152 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(Train_Genrator.class_indices,\"\\n\")\n",
    "print(Train_Genrator.classes,\"\\n\")\n",
    "print(len(Train_Genrator.filenames),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7163fc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(img_hight,img_width,3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c6f37e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 2s/step - accuracy: 0.5096 - loss: 0.9106\n",
      "Epoch 2/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 843us/step - accuracy: 0.6875 - loss: 0.6115\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 902ms/step - accuracy: 0.8107 - loss: 0.4539\n",
      "Epoch 4/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264us/step - accuracy: 0.8750 - loss: 0.3547 \n",
      "Epoch 5/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 917ms/step - accuracy: 0.8921 - loss: 0.2780\n",
      "Epoch 6/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 227us/step - accuracy: 0.9062 - loss: 0.1509 \n",
      "Epoch 7/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 910ms/step - accuracy: 0.9002 - loss: 0.2443\n",
      "Epoch 8/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520us/step - accuracy: 0.9375 - loss: 0.2881 \n",
      "Epoch 9/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 914ms/step - accuracy: 0.9307 - loss: 0.1908\n",
      "Epoch 10/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 409us/step - accuracy: 0.8125 - loss: 0.3109 \n",
      "Epoch 11/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 884ms/step - accuracy: 0.9302 - loss: 0.1540\n",
      "Epoch 12/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 436us/step - accuracy: 0.9688 - loss: 0.1088 \n",
      "Epoch 13/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 881ms/step - accuracy: 0.9410 - loss: 0.1428\n",
      "Epoch 14/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 267us/step - accuracy: 0.9375 - loss: 0.1144 \n",
      "Epoch 15/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 916ms/step - accuracy: 0.9610 - loss: 0.1121\n",
      "Epoch 16/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 411us/step - accuracy: 0.9688 - loss: 0.1427 \n",
      "Epoch 17/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 886ms/step - accuracy: 0.9288 - loss: 0.1873\n",
      "Epoch 18/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 374us/step - accuracy: 0.9375 - loss: 0.1545 \n",
      "Epoch 19/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 899ms/step - accuracy: 0.9128 - loss: 0.2331\n",
      "Epoch 20/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509us/step - accuracy: 0.9375 - loss: 0.1492 \n",
      "Epoch 21/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 900ms/step - accuracy: 0.9644 - loss: 0.0976\n",
      "Epoch 22/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 353us/step - accuracy: 0.9688 - loss: 0.0463 \n",
      "Epoch 23/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 881ms/step - accuracy: 0.9601 - loss: 0.1078\n",
      "Epoch 24/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 252us/step - accuracy: 1.0000 - loss: 0.0286 \n",
      "Epoch 25/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 882ms/step - accuracy: 0.9480 - loss: 0.1450\n",
      "Epoch 26/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163us/step - accuracy: 0.9688 - loss: 0.1582 \n",
      "Epoch 27/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 899ms/step - accuracy: 0.9632 - loss: 0.0921\n",
      "Epoch 28/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329us/step - accuracy: 0.9688 - loss: 0.0839 \n",
      "Epoch 29/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 909ms/step - accuracy: 0.9644 - loss: 0.0875\n",
      "Epoch 30/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 303us/step - accuracy: 0.9688 - loss: 0.0521 \n",
      "Epoch 31/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 889ms/step - accuracy: 0.9698 - loss: 0.0742\n",
      "Epoch 32/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 273us/step - accuracy: 1.0000 - loss: 0.0542 \n",
      "Epoch 33/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 885ms/step - accuracy: 0.9573 - loss: 0.1118\n",
      "Epoch 34/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 193us/step - accuracy: 0.9688 - loss: 0.0901 \n",
      "Epoch 35/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 884ms/step - accuracy: 0.9750 - loss: 0.0713\n",
      "Epoch 36/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342us/step - accuracy: 0.9688 - loss: 0.0382 \n",
      "Epoch 37/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 948ms/step - accuracy: 0.9777 - loss: 0.0600\n",
      "Epoch 38/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 299us/step - accuracy: 0.9688 - loss: 0.1193 \n",
      "Epoch 39/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 902ms/step - accuracy: 0.9730 - loss: 0.0801\n",
      "Epoch 40/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 190us/step - accuracy: 0.9688 - loss: 0.0836 \n",
      "Epoch 41/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 883ms/step - accuracy: 0.9851 - loss: 0.0490\n",
      "Epoch 42/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 246us/step - accuracy: 1.0000 - loss: 0.0153 \n",
      "Epoch 43/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 887ms/step - accuracy: 0.9813 - loss: 0.0481\n",
      "Epoch 44/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 350us/step - accuracy: 1.0000 - loss: 0.0070 \n",
      "Epoch 45/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 890ms/step - accuracy: 0.9746 - loss: 0.0653\n",
      "Epoch 46/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 368us/step - accuracy: 0.9688 - loss: 0.1698 \n",
      "Epoch 47/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 880ms/step - accuracy: 0.9812 - loss: 0.0463\n",
      "Epoch 48/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143us/step - accuracy: 0.9375 - loss: 0.1877 \n",
      "Epoch 49/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 894ms/step - accuracy: 0.9886 - loss: 0.0368\n",
      "Epoch 50/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354us/step - accuracy: 0.9375 - loss: 0.0718 \n",
      "Epoch 51/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 908ms/step - accuracy: 0.9867 - loss: 0.0406\n",
      "Epoch 52/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 197us/step - accuracy: 0.9375 - loss: 0.1944 \n",
      "Epoch 53/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 887ms/step - accuracy: 0.9556 - loss: 0.1126\n",
      "Epoch 54/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 454us/step - accuracy: 1.0000 - loss: 0.0154 \n",
      "Epoch 55/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 894ms/step - accuracy: 0.9700 - loss: 0.0724\n",
      "Epoch 56/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 294us/step - accuracy: 1.0000 - loss: 0.0279 \n",
      "Epoch 57/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 888ms/step - accuracy: 0.9795 - loss: 0.0509\n",
      "Epoch 58/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 237us/step - accuracy: 1.0000 - loss: 0.0324 \n",
      "Epoch 59/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 807ms/step - accuracy: 0.9707 - loss: 0.0842\n",
      "Epoch 60/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 237us/step - accuracy: 1.0000 - loss: 0.0390 \n",
      "Epoch 61/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 717ms/step - accuracy: 0.9583 - loss: 0.0968\n",
      "Epoch 62/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0s/step - accuracy: 0.9688 - loss: 0.1026    \n",
      "Epoch 63/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 724ms/step - accuracy: 0.9847 - loss: 0.0447\n",
      "Epoch 64/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8us/step - accuracy: 1.0000 - loss: 0.0072   \n",
      "Epoch 65/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 728ms/step - accuracy: 0.9859 - loss: 0.0399\n",
      "Epoch 66/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 254us/step - accuracy: 0.9688 - loss: 0.0904 \n",
      "Epoch 67/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 721ms/step - accuracy: 0.9947 - loss: 0.0204\n",
      "Epoch 68/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118us/step - accuracy: 1.0000 - loss: 0.0212 \n",
      "Epoch 69/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 723ms/step - accuracy: 0.9754 - loss: 0.0696\n",
      "Epoch 70/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 253us/step - accuracy: 1.0000 - loss: 0.0105 \n",
      "Epoch 71/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 717ms/step - accuracy: 0.9901 - loss: 0.0250\n",
      "Epoch 72/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 246us/step - accuracy: 1.0000 - loss: 4.4163e-04 \n",
      "Epoch 73/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 717ms/step - accuracy: 0.9908 - loss: 0.0257\n",
      "Epoch 74/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18us/step - accuracy: 0.9688 - loss: 0.1046  \n",
      "Epoch 75/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 718ms/step - accuracy: 0.9737 - loss: 0.0726\n",
      "Epoch 76/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 238us/step - accuracy: 1.0000 - loss: 0.0049 \n",
      "Epoch 77/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 726ms/step - accuracy: 0.9884 - loss: 0.0277\n",
      "Epoch 78/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 237us/step - accuracy: 0.9688 - loss: 0.0446 \n",
      "Epoch 79/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 726ms/step - accuracy: 0.9941 - loss: 0.0138\n",
      "Epoch 80/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0s/step - accuracy: 1.0000 - loss: 0.0065    \n",
      "Epoch 81/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 784ms/step - accuracy: 0.9898 - loss: 0.0281\n",
      "Epoch 82/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 255us/step - accuracy: 1.0000 - loss: 0.0025 \n",
      "Epoch 83/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 721ms/step - accuracy: 0.9889 - loss: 0.0334\n",
      "Epoch 84/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 278us/step - accuracy: 0.9688 - loss: 0.0647 \n",
      "Epoch 85/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 717ms/step - accuracy: 0.9872 - loss: 0.0353\n",
      "Epoch 86/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 240us/step - accuracy: 0.9688 - loss: 0.0893 \n",
      "Epoch 87/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 719ms/step - accuracy: 0.9809 - loss: 0.0461\n",
      "Epoch 88/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0s/step - accuracy: 1.0000 - loss: 0.0198    \n",
      "Epoch 89/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 722ms/step - accuracy: 0.9912 - loss: 0.0262\n",
      "Epoch 90/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 253us/step - accuracy: 0.9688 - loss: 0.0413 \n",
      "Epoch 91/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 721ms/step - accuracy: 0.9681 - loss: 0.0995\n",
      "Epoch 92/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 237us/step - accuracy: 1.0000 - loss: 1.3715e-04 \n",
      "Epoch 93/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 731ms/step - accuracy: 0.9651 - loss: 0.0743\n",
      "Epoch 94/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 235us/step - accuracy: 1.0000 - loss: 0.0126 \n",
      "Epoch 95/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 773ms/step - accuracy: 0.9883 - loss: 0.0264\n",
      "Epoch 96/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 271us/step - accuracy: 1.0000 - loss: 0.0222 \n",
      "Epoch 97/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 909ms/step - accuracy: 0.9927 - loss: 0.0216\n",
      "Epoch 98/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 199us/step - accuracy: 1.0000 - loss: 5.6147e-04 \n",
      "Epoch 99/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 802ms/step - accuracy: 0.9935 - loss: 0.0151\n",
      "Epoch 100/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 198us/step - accuracy: 0.9688 - loss: 0.0319 \n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    Train_Genrator,\n",
    "    steps_per_epoch=Train_Genrator.samples // batch_size,\n",
    "    epochs=100,\n",
    "    verbose=1 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25e68083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "model_save_name = 'clasifier.pt'\n",
    "path= F\"C:/Users/Admin/OneDrive/Desktop/Yash/python/pic/{model_save_name}\"\n",
    "torch.save(model,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "843e2e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model_path = 'C:/Users/Admin/OneDrive/Desktop/Yash/python/pic/clasifier.pt'\n",
    "model = torch.load(model_path, map_location=torch.device('cpu'),  weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20e66209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "feea5b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "The predicted class for img is: Potato___healthy\n"
     ]
    }
   ],
   "source": [
    "img_path = 'C:/Users/Admin/OneDrive/Desktop/potato.jpeg'\n",
    "img = image.load_img(img_path, target_size=(img_hight,img_width))\n",
    "img_arry= image.img_to_array(img)\n",
    "img_arry = np.expand_dims(img_arry, axis=0)\n",
    "img_arry /= 255.\n",
    "\n",
    "pridictions = model.predict(img_arry)\n",
    "classes = Train_Genrator.class_indices\n",
    "predicted_class = list(classes.keys())[np.argmax(pridictions)]\n",
    "\n",
    "print(f\"The predicted class for img is: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b4fd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1e29449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step\n",
      "The predicted class for img is: Potato___Early_blight\n"
     ]
    }
   ],
   "source": [
    "img_path = 'C:/Users/Admin/OneDrive/Desktop/potato_p.jpeg'\n",
    "img = image.load_img(img_path, target_size=(img_hight,img_width))\n",
    "img_arry= image.img_to_array(img)\n",
    "img_arry = np.expand_dims(img_arry, axis=0)\n",
    "img_arry /= 255.\n",
    "\n",
    "pridictions = model.predict(img_arry)\n",
    "classes = Train_Genrator.class_indices\n",
    "predicta_class = list(classes.keys())[np.argmax(pridictions)]\n",
    "\n",
    "print(f\"The predicted class for img is: {predicta_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec0164f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f350f962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "The predicted class for img is: Potato___Early_blight\n"
     ]
    }
   ],
   "source": [
    "img_path = 'C:/Users/Admin/OneDrive/Desktop/pateto_let.jpeg'\n",
    "img = image.load_img(img_path, target_size=(img_hight,img_width))\n",
    "img_arry= image.img_to_array(img)\n",
    "img_arry = np.expand_dims(img_arry, axis=0)\n",
    "img_arry /= 255.\n",
    "\n",
    "pridictions = model.predict(img_arry)\n",
    "classes = Train_Genrator.class_indices\n",
    "predicta_class = list(classes.keys())[np.argmax(pridictions)]\n",
    "\n",
    "print(f\"The predicted class for img is: {predicta_class}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
